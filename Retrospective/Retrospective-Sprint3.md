# RETROSPECTIVE  SPRINT #3 (Team 8)

## PROCESS MEASURES 

### Macro statistics
##### Committed stories:
- Browse Applications Decisions (8 story points)
- Browse Proposals (5 story points)
- Update Proposal (8 story points)
- Notify Application Decision (13 story points)

##### Number of stories  
Committed: 4
Done: 4


##### Total points  
Committed: Overall 34 
Done: 34

##### Nr of hours planned vs. spent (as a team)  
Planned: 110 
Spent: 106.25


#### Our definition of done:

- Unit Tests passing
- Code review completed
- Code present on VCS
- End-to-End tests performed
- Dockerize each component


### Detailed statistics

We are reporting data for all stories as if we completed them

| Story  | # Tasks | Points | Hours est. | Hours actual |
|--------|---------|--------|------------|--------------|
| _#0_   |   7 |   N/A  | 23  | 22.75  |
|_#1_   |   4 | 8 | 17  |  16 |
| _#2_|  4 | 5 |20 | 19 |
| _#3_ | 4 | 8 |28 | 27 |
| _#4_ | 4| 13 |22 | 22 |



##### Points/issues that specifically emerge from comparison between hour estimation and actual:
- We slightly overestimated our tasks to ensure that we have enough time left for continous testing and feedback. 

##### Hours per task average, standard deviation (estimate and actual):
##### Estimate:
  - hours per task average: 4.4
  - standard deviation: 7.071
##### Actual:  
  - hours per task average:  4.25
  - standard deviation: 7.9


##### Total task estimation error ratio: sum of total hours estimation / sum of total hours spent - 1  

  - (110/106.25 - 1) = 0.03

## QUALITY MEASURES 

- Unit Testing:
  - Total hours estimated: 16h
  - Total hours spent: 16h
  - Nr of automated unit test cases :88
  - Coverage (if available): (refer to the image)

- E2E testing:
  - Total hours estimated: 4h
  - We opened a total of 11 issues out of 6 were resolved based on the priority of invalid, bugs, and then enhancement. 
             
- Code review 
  - Total hours estimated : 12h
  - Total hours spent : 12h
  

## ASSESSMENT

**What caused your errors in estimation (if any)?**
- There were no errors in our estimation. However, we were quite efficient in this sprint and added 2 more stories. 
  
**What lessons did you learn (both positive and negative) in this sprint?**

**Negative lesson** (the biggest one):  
- There are no negative lessons.

**Positive lesson**:  
- We enhanced our design based on the continous improvement and feedback from our team members (e.g. adding dark mode etc.)
- We improved the test coverage for all controllers and executed a large number of test functions with varying scenarios.
- We completed all stories committed for this sprint according to the DOD and added two more stories towards the mid of sprint.

**Which improvement goals set in the previous retrospective were you able to achieve?**
- In the last sprint, we had an issue with not identifying components common to all stories, however in this sprint planning we had a detailed discussion on the approach for each story with varying test scenarios so we could all be on the same page. 

**Which ones you were not able to achieve? Why?**
- Not applicable.

**Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.)**
- There are no improvement goals but we hope to achieve the same velocity as this sprint. 

**One thing you are proud of as a Team!!**
- As a team, we have improved the test coverage significantly. We also improved the design of our UI which we really like and our proud of. Moreover, the notifications that we have implemented provides notifications for all actions. 
